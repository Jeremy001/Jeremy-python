{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载包\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "base_url = 'http://www.ochirly.com.cn'\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 UBrowser/6.1.2107.204 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "服装\n",
      "连衣裙\n",
      "/Clothing/Dresses/list.shtml\n",
      "服装\n",
      "毛织\n",
      "/Clothing/Sweaters/list.shtml\n",
      "服装\n",
      "T恤\n",
      "/Clothing/T_Shirts/list.shtml\n",
      "服装\n",
      "衬衫\n",
      "/Clothing/Shirts/list.shtml\n",
      "服装\n",
      "半截裙\n",
      "/Clothing/Skirts/list.shtml\n",
      "服装\n",
      "裤装\n",
      "/Clothing/Pants/list.shtml\n",
      "服装\n",
      "外套\n",
      "/Clothing/Jakets/list.shtml\n",
      "服装\n",
      "呢料外套\n",
      "/Clothing/Worsted_Coats/list.shtml\n"
     ]
    }
   ],
   "source": [
    "# 获取服装各品类名称和URL、近期上市日期和URL、场景名称和URL\n",
    "# 获取主页\n",
    "base_page = requests.get(base_url, headers = header)\n",
    "base_source = BeautifulSoup(base_page.content, 'html.parser', from_encoding = 'gb18030')\n",
    "# 把结果写入到csv文件中\n",
    "csv_file = open('ochirly_category.csv', \n",
    "                'w', \n",
    "                newline = '', \n",
    "                encoding = 'utf-8-sig')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['cat1', 'cat2', 'url', 'page_num'])\n",
    "## 1. 场景购\n",
    "for level in base_source.find(attrs = {'data-catalogid':'4940'}).find_all('li')[1:]:\n",
    "    cat1 = '场景'\n",
    "    cat2 = level.string\n",
    "    url_a = level.find_all('a')\n",
    "    for a in url_a:\n",
    "        url = a.get('href')\n",
    "        url1 = base_url + url\n",
    "        page1 = requests.get(url1, headers = hearder)\n",
    "        source1 = BeautifulSoup(page1.content, 'html.parser', from_encoding = 'gb13030')\n",
    "        page_num = source1.find('div', class_ = 'f_r_page').find('input').previous_sibling\n",
    "        # 写入 csv 文件\n",
    "        csv_writer.writerow([cat1, cat2, url])\n",
    "## 2. 新品\n",
    "for level in base_source.find(attrs = {'data-catalogid':'23'}).find_all('li')[1:6]:\n",
    "    cat1 = '新品'\n",
    "    cat2 = level.string\n",
    "    url_a = level.find_all('a')\n",
    "    for a in url_a:\n",
    "        url = a.get('href')\n",
    "        # 写入 csv 文件\n",
    "        csv_writer.writerow([cat1, cat2, url])\n",
    "## 3. 服装\n",
    "for level in base_source.find(attrs = {'data-catalogid':'3'}).find_all('li')[1:]:\n",
    "    cat1 = '服装'\n",
    "    cat2 = level.string\n",
    "    url_a = level.find_all('a')\n",
    "    for a in url_a:\n",
    "        url = a.get('href')\n",
    "        # 写入 csv 文件\n",
    "        csv_writer.writerow([cat1, cat2, url])        \n",
    "# 关闭 csv 文件\n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
